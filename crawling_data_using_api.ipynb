{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import json\n",
    "import requests \n",
    "from clickhouse_driver import Client\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_json(method, url, params):\n",
    "    \"\"\"\n",
    "    function for crawling\n",
    "    raise error when http status code is not 200 (success).\n",
    "    \n",
    "    @param method: (str)  http method for request\n",
    "    @param url   : (str)  request url\n",
    "    @param params: (dict) parameter for request\n",
    "    \"\"\"\n",
    "    if method == 'get':\n",
    "        res = requests.get(url, params=params)\n",
    "    elif method == 'post':\n",
    "        res = requests.post(URL, data=json.dumps(data))\n",
    "        \n",
    "    res.raise_for_status()\n",
    "    \n",
    "    return res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API를 활용한 크롤링\n",
    "* 데이터를 가져온 url은 공개하지 않겠음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json') as f:\n",
    "    json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 대분류와 중분류 가져오기\n",
    "\n",
    "`Example`\n",
    "```python\n",
    "# sample\n",
    "list_url = json_data['get_crawldata']['get_category_url']\n",
    "list_param = {\n",
    "    'display': 'tree',\n",
    "    'kind': 'category',\n",
    "    'lang': 'ko',\n",
    "    'v': 'v1'\n",
    "}\n",
    "\n",
    "crawl_json('get', list_url, list_param)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test['tags'][1]['title']\n",
    "# test['tags'][1]['id']\n",
    "\n",
    "# test['tags'][1]['tags'][0]['title']\n",
    "# test['tags'][1]['tags'][0]['id']\n",
    "# test['tags'][1]['tags'][0]['converted_tag_for_url']\n",
    "# test['tags'][1]['tags'][0]['count_job']\n",
    "# test['tags'][1]['tags'][0]['count_user']\n",
    "\n",
    "list_url = json_data['get_crawldata']['get_category_url']\n",
    "\n",
    "list_param = {\n",
    "    'display': 'tree',\n",
    "    'kind': 'category',\n",
    "    'lang': 'ko',\n",
    "    'v': 'v1'\n",
    "}\n",
    "\n",
    "contents = crawl_json('get', list_url, list_param)\n",
    "\n",
    "\n",
    "main_df = pd.DataFrame()\n",
    "main_lst = []\n",
    "_col_lst = ['main_cate', 'main_cate_id', 'main_cate_en', 'medium_cate', 'medium_cate_id', 'medium_cate_en', 'medium_cate_cnt_job', 'medium_cate_cnt_user']\n",
    "for i in range(len(contents['tags'])):\n",
    "    \n",
    "    _main_lst = [[contents['tags'][i]['title'], contents['tags'][i]['id'], contents['tags'][i]['mapping_legacy'], contents['tags'][i]['tags'][j]['title'], contents['tags'][i]['tags'][j]['id'], contents['tags'][i]['tags'][j]['converted_tag_for_url'], contents['tags'][i]['tags'][j]['count_job'], contents['tags'][i]['tags'][j]['count_user']] if contents['tags'][i]['mapping_legacy']!= None else [contents['tags'][i]['title'], contents['tags'][i]['id'], contents['tags'][i]['title'], contents['tags'][i]['tags'][j]['title'], contents['tags'][i]['tags'][j]['id'], contents['tags'][i]['tags'][j]['converted_tag_for_url'], contents['tags'][i]['tags'][j]['count_job'], contents['tags'][i]['tags'][j]['count_user']] for j in range(len(contents['tags'][i]['tags']))]    \n",
    "#     _main_lst = [test['tags'][i]['title'], test['tags'][i]['id'], test['tags'][i]['mapping_legacy'], test['tags'][i]['tags'][0]['title'], test['tags'][i]['tags'][0]['id'], test['tags'][i]['tags'][0]['converted_tag_for_url'], test['tags'][i]['tags'][0]['count_job'], test['tags'][i]['tags'][0]['count_user']]\n",
    "        \n",
    "    _main_df = pd.DataFrame(_main_lst, columns=_col_lst)\n",
    "\n",
    "    main_df = main_df.append(_main_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_cate</th>\n",
       "      <th>main_cate_id</th>\n",
       "      <th>main_cate_en</th>\n",
       "      <th>medium_cate</th>\n",
       "      <th>medium_cate_id</th>\n",
       "      <th>medium_cate_en</th>\n",
       "      <th>medium_cate_cnt_job</th>\n",
       "      <th>medium_cate_cnt_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F&amp;B</td>\n",
       "      <td>10057</td>\n",
       "      <td>F&amp;B</td>\n",
       "      <td>식품 MD</td>\n",
       "      <td>761</td>\n",
       "      <td>food md</td>\n",
       "      <td>8</td>\n",
       "      <td>2109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F&amp;B</td>\n",
       "      <td>10057</td>\n",
       "      <td>F&amp;B</td>\n",
       "      <td>요리사</td>\n",
       "      <td>748</td>\n",
       "      <td>chef</td>\n",
       "      <td>6</td>\n",
       "      <td>4150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F&amp;B</td>\n",
       "      <td>10057</td>\n",
       "      <td>F&amp;B</td>\n",
       "      <td>외식업 종사자</td>\n",
       "      <td>749</td>\n",
       "      <td>restaurant worker</td>\n",
       "      <td>4</td>\n",
       "      <td>5878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F&amp;B</td>\n",
       "      <td>10057</td>\n",
       "      <td>F&amp;B</td>\n",
       "      <td>바텐더</td>\n",
       "      <td>747</td>\n",
       "      <td>bartender</td>\n",
       "      <td>2</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F&amp;B</td>\n",
       "      <td>10057</td>\n",
       "      <td>F&amp;B</td>\n",
       "      <td>외식업 메뉴 개발자</td>\n",
       "      <td>10058</td>\n",
       "      <td>restaurant management</td>\n",
       "      <td>2</td>\n",
       "      <td>1856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  main_cate  main_cate_id main_cate_en medium_cate  medium_cate_id  \\\n",
       "0       F&B         10057          F&B       식품 MD             761   \n",
       "1       F&B         10057          F&B         요리사             748   \n",
       "2       F&B         10057          F&B     외식업 종사자             749   \n",
       "3       F&B         10057          F&B         바텐더             747   \n",
       "4       F&B         10057          F&B  외식업 메뉴 개발자           10058   \n",
       "\n",
       "          medium_cate_en  medium_cate_cnt_job  medium_cate_cnt_user  \n",
       "0                food md                    8                  2109  \n",
       "1                   chef                    6                  4150  \n",
       "2      restaurant worker                    4                  5878  \n",
       "3              bartender                    2                  1004  \n",
       "4  restaurant management                    2                  1856  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_cate_id, medium_cate, medium_cate_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 중분류 마다 구인을 하고 있는 회사 리스트 가져오기\n",
    "관심있는 직군에서만 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F&B' '개발' '건설, 시설' '게임 제작' '경영, 비즈니스' '고객서비스, 리테일' '디자인' '마케팅, 광고'\n",
      " '물류, 무역' '미디어' '법률, 법집행기관' '엔지니어링, 설계' '영업' '의료, 제약, 바이오' '인사, 교육'\n",
      " '정부, 비영리' '제조, 생산' '금융']\n",
      "['식품 MD' '요리사' '외식업 종사자' '바텐더' '외식업 메뉴 개발자' '레스토랑 관리자' '영양사' '제과제빵사'\n",
      " '서버 개발자' '웹 개발자']\n"
     ]
    }
   ],
   "source": [
    "print(main_df['main_cate'].unique())\n",
    "print(main_df['medium_cate'].unique()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookmark_cate_lst = ['데이터 엔지니어', '빅데이터 엔지니어', '데이터 사이언티스트', '머신러닝 엔지니어', '서비스 기획자', '사업개발,기획자', '프로젝트 매니저', '전략 기획자', '데이터 분석가']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_cate</th>\n",
       "      <th>main_cate_id</th>\n",
       "      <th>main_cate_en</th>\n",
       "      <th>medium_cate</th>\n",
       "      <th>medium_cate_id</th>\n",
       "      <th>medium_cate_en</th>\n",
       "      <th>medium_cate_cnt_job</th>\n",
       "      <th>medium_cate_cnt_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>개발</td>\n",
       "      <td>518</td>\n",
       "      <td>Development</td>\n",
       "      <td>데이터 엔지니어</td>\n",
       "      <td>655</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>198</td>\n",
       "      <td>9375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>개발</td>\n",
       "      <td>518</td>\n",
       "      <td>Development</td>\n",
       "      <td>데이터 사이언티스트</td>\n",
       "      <td>1024</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>133</td>\n",
       "      <td>6185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>개발</td>\n",
       "      <td>518</td>\n",
       "      <td>Development</td>\n",
       "      <td>머신러닝 엔지니어</td>\n",
       "      <td>1634</td>\n",
       "      <td>machine learning engineer</td>\n",
       "      <td>133</td>\n",
       "      <td>4626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>개발</td>\n",
       "      <td>518</td>\n",
       "      <td>Development</td>\n",
       "      <td>빅데이터 엔지니어</td>\n",
       "      <td>1025</td>\n",
       "      <td>big data engineer</td>\n",
       "      <td>112</td>\n",
       "      <td>4874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>경영, 비즈니스</td>\n",
       "      <td>507</td>\n",
       "      <td>Business</td>\n",
       "      <td>서비스 기획자</td>\n",
       "      <td>565</td>\n",
       "      <td>service planner</td>\n",
       "      <td>282</td>\n",
       "      <td>15356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>경영, 비즈니스</td>\n",
       "      <td>507</td>\n",
       "      <td>Business</td>\n",
       "      <td>사업개발,기획자</td>\n",
       "      <td>564</td>\n",
       "      <td>business development</td>\n",
       "      <td>255</td>\n",
       "      <td>18484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>경영, 비즈니스</td>\n",
       "      <td>507</td>\n",
       "      <td>Business</td>\n",
       "      <td>프로젝트 매니저</td>\n",
       "      <td>559</td>\n",
       "      <td>project manager</td>\n",
       "      <td>228</td>\n",
       "      <td>15684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>경영, 비즈니스</td>\n",
       "      <td>507</td>\n",
       "      <td>Business</td>\n",
       "      <td>전략 기획자</td>\n",
       "      <td>563</td>\n",
       "      <td>strategic planner</td>\n",
       "      <td>180</td>\n",
       "      <td>15768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>경영, 비즈니스</td>\n",
       "      <td>507</td>\n",
       "      <td>Business</td>\n",
       "      <td>데이터 분석가</td>\n",
       "      <td>656</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>111</td>\n",
       "      <td>7675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   main_cate  main_cate_id main_cate_en medium_cate  medium_cate_id  \\\n",
       "15        개발           518  Development    데이터 엔지니어             655   \n",
       "20        개발           518  Development  데이터 사이언티스트            1024   \n",
       "21        개발           518  Development   머신러닝 엔지니어            1634   \n",
       "23        개발           518  Development   빅데이터 엔지니어            1025   \n",
       "65  경영, 비즈니스           507     Business     서비스 기획자             565   \n",
       "66  경영, 비즈니스           507     Business    사업개발,기획자             564   \n",
       "67  경영, 비즈니스           507     Business    프로젝트 매니저             559   \n",
       "68  경영, 비즈니스           507     Business      전략 기획자             563   \n",
       "70  경영, 비즈니스           507     Business     데이터 분석가             656   \n",
       "\n",
       "               medium_cate_en  medium_cate_cnt_job  medium_cate_cnt_user  \n",
       "15              data engineer                  198                  9375  \n",
       "20             data scientist                  133                  6185  \n",
       "21  machine learning engineer                  133                  4626  \n",
       "23          big data engineer                  112                  4874  \n",
       "65            service planner                  282                 15356  \n",
       "66       business development                  255                 18484  \n",
       "67            project manager                  228                 15684  \n",
       "68          strategic planner                  180                 15768  \n",
       "70               data analyst                  111                  7675  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df[main_df['medium_cate'].isin(bookmark_cate_lst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.wanted.co.kr/api/v4/jobs'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data['get_crawldata']['get_company_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main_df[main_df['medium_cate'].isin(bookmark_cate_lst)].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518 데이터 엔지니어 655\n",
      "offset_num: 0\n",
      "offset_num: 100\n",
      "====> There is No more offset_num: 200\n",
      "end\n",
      "518 데이터 사이언티스트 1024\n",
      "offset_num: 0\n",
      "offset_num: 100\n",
      "====> There is No more offset_num: 200\n",
      "end\n",
      "518 머신러닝 엔지니어 1634\n",
      "offset_num: 0\n",
      "offset_num: 100\n",
      "====> There is No more offset_num: 200\n",
      "end\n",
      "518 빅데이터 엔지니어 1025\n",
      "offset_num: 0\n",
      "offset_num: 100\n",
      "====> There is No more offset_num: 200\n",
      "end\n",
      "507 서비스 기획자 565\n",
      "offset_num: 0\n",
      "offset_num: 100\n",
      "offset_num: 200\n",
      "====> There is No more offset_num: 300\n",
      "end\n",
      "507 사업개발,기획자 564\n",
      "offset_num: 0\n",
      "offset_num: 100\n",
      "offset_num: 200\n",
      "====> There is No more offset_num: 300\n",
      "end\n",
      "507 프로젝트 매니저 559\n",
      "offset_num: 0\n",
      "offset_num: 100\n",
      "offset_num: 200\n",
      "====> There is No more offset_num: 300\n",
      "end\n",
      "507 전략 기획자 563\n",
      "offset_num: 0\n",
      "offset_num: 100\n",
      "====> There is No more offset_num: 200\n",
      "end\n",
      "507 데이터 분석가 656\n",
      "offset_num: 0\n",
      "====> There is No more offset_num: 100\n",
      "end\n",
      "00:01:16\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "##### loop medium_cate #####\n",
    "list_url = json_data['get_crawldata']['get_company_url']\n",
    "total_df = pd.DataFrame()\n",
    "\n",
    "### SET\n",
    "limit_num = 100\n",
    "\n",
    "for i in range(len(df)):\n",
    "    MAIN_CATE_ID = df.iloc[i]['main_cate_id']\n",
    "    MEDIUM_CATE = df.iloc[i]['medium_cate']\n",
    "    MEDIUM_CATE_ID = df.iloc[i]['medium_cate_id']\n",
    "    \n",
    "    print(MAIN_CATE_ID, MEDIUM_CATE, MEDIUM_CATE_ID)\n",
    "    \n",
    "    ### SET \n",
    "    learning_state = True\n",
    "    offset_num = 0\n",
    "    entire_data = []\n",
    "\n",
    "    \n",
    "    while learning_state:\n",
    "\n",
    "        list_param = {\n",
    "        'country': 'kr',\n",
    "        'tag_type_id': str(MEDIUM_CATE_ID),\n",
    "        'job_sort': 'job.latest_order',\n",
    "        'years': -1,\n",
    "        'locations': 'all',\n",
    "        'offset': offset_num,\n",
    "        'limit': limit_num}\n",
    "\n",
    "        list_res = crawl_json('get', list_url, list_param) # data가 있는지 없는지 확인하기 위함\n",
    "\n",
    "        if list_res['data'] == None: # 데이터가 없으면 learning_state = False 로 주어 다음이 안 돌아가도록 함\n",
    "            print(\"====> There is No more offset_num: {}\".format(offset_num))\n",
    "            print('end')\n",
    "            learning_state = False\n",
    "\n",
    "        else: # 데이터가 있는 경우는 계속 저장\n",
    "            print(\"offset_num: {}\".format(offset_num))\n",
    "    #         print(list_res)\n",
    "            entire_data += list_res['data']\n",
    "#             offset_num += 1\n",
    "            offset_num += limit_num\n",
    "            \n",
    "        if (offset_num%120 == 0 and offset_num!=0):\n",
    "            wait_min = 15\n",
    "            print(\"Sleep {}min\".format(15/60))\n",
    "            time.sleep(wait_min/60)\n",
    "    \n",
    "    \n",
    "    # ENTIRE_DATA NEED PARSING\n",
    "    info_col_name = ['company_name', 'company_id', 'industry_name', 'country', 'location', 'job_id', 'job_position', 'job_like_count']\n",
    "    list_info = [[i['company']['name'], i['company']['id'], i['company']['industry_name'], i['address']['country'], i['address']['location'], i['id'], i['position'],  i['like_count']] for i in entire_data]\n",
    "#     print(list_info)\n",
    "#     print(info_col_name)\n",
    "    \n",
    "    \n",
    "    # set main_cate_id, medium_cate, medium_cate_id\n",
    "    _total_df = pd.DataFrame(list_info, columns=info_col_name)\n",
    "    _total_df['main_cate_id'] = MAIN_CATE_ID\n",
    "    _total_df['medium_cate'] = MEDIUM_CATE\n",
    "    _total_df['medium_cate_id'] = MEDIUM_CATE_ID\n",
    "    \n",
    "    # val_columns 은 Column명 정의\n",
    "#     print(\"===> To Clickhouse database\")\n",
    "#     client.execute('INSERT INTO crawl.wanted_job_id ({}) VALUES'.format(val_columns), _total_df.values.tolist())\n",
    "    \n",
    "#     print(_total_df.head())\n",
    "    \n",
    "    total_df = total_df.append(_total_df, ignore_index=True)\n",
    "\n",
    "    \n",
    "elapsed_time = time.time() - start_time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['company_name', 'company_id', 'industry_name', 'country', 'location',\n",
      "       'job_id', 'job_position', 'job_like_count', 'main_cate_id',\n",
      "       'medium_cate', 'medium_cate_id'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>29199</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9000</td>\n",
       "      <td>39671</td>\n",
       "      <td>데이터베이스 관리자(DBA)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1628</td>\n",
       "      <td>28331</td>\n",
       "      <td>Search Service Backend Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3606</td>\n",
       "      <td>36523</td>\n",
       "      <td>DBA(Database Engineer)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5866</td>\n",
       "      <td>27569</td>\n",
       "      <td>빅데이터/그래프데이터 분석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>137</td>\n",
       "      <td>30399</td>\n",
       "      <td>VC전략팀 시니어</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>886</td>\n",
       "      <td>29182</td>\n",
       "      <td>[인텔리전스랩스] 분석지원팀 데이터 분석가</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>331</td>\n",
       "      <td>25065</td>\n",
       "      <td>서비스 기획자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>2330</td>\n",
       "      <td>23846</td>\n",
       "      <td>Data Privacy Lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>3091</td>\n",
       "      <td>19416</td>\n",
       "      <td>플랫폼 기획자</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1465 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      company_id  job_id                     job_position\n",
       "0             90   29199                   Data Scientist\n",
       "1           9000   39671                  데이터베이스 관리자(DBA)\n",
       "2           1628   28331  Search Service Backend Engineer\n",
       "3           3606   36523           DBA(Database Engineer)\n",
       "4           5866   27569                   빅데이터/그래프데이터 분석\n",
       "...          ...     ...                              ...\n",
       "1460         137   30399                        VC전략팀 시니어\n",
       "1461         886   29182          [인텔리전스랩스] 분석지원팀 데이터 분석가\n",
       "1462         331   25065                          서비스 기획자\n",
       "1463        2330   23846                Data Privacy Lead\n",
       "1464        3091   19416                          플랫폼 기획자\n",
       "\n",
       "[1465 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(total_df.columns)\n",
    "total_df[['company_id', 'job_id', 'job_position']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 각 상세정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df = total_df[['company_id', 'company_name', 'job_id', 'job_position', 'medium_cate_id', 'medium_cate', 'location']].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobDesc(i):\n",
    "    \"\"\"\n",
    "    i(int): indes of Dataframe\n",
    "    \"\"\"\n",
    "    detail_url = base_url.format(job_df.iloc[i]['job_id'])\n",
    "    detail_res = crawl_json('get', detail_url, {}) \n",
    "    detail = detail_res['job']['detail']\n",
    "    \n",
    "    for k, v in detail.items():\n",
    "        detail[k] = [re.sub(r'[\\t\\r\\n]', '', s) for s in re.split('[•|-]', detail[k]) if s not in ['']] \n",
    "        \n",
    "    \n",
    "    company_id = job_df.iloc[i]['company_id']\n",
    "    company_name = job_df.iloc[i]['company_name']\n",
    "    job_id = job_df.iloc[i]['job_id']\n",
    "    job_position = job_df.iloc[i]['job_position']\n",
    "    medium_cate_id = job_df.iloc[i]['medium_cate_id']\n",
    "    medium_cate = job_df.iloc[i]['medium_cate']\n",
    "    location = job_df.iloc[i]['location']\n",
    "    \n",
    "    desc_col_list = ['requirements', 'main_tasks', 'preferred_points', 'benefits', 'intro']\n",
    "    \n",
    "    desc_dict = {}\n",
    "    \n",
    "    for ii in desc_col_list:\n",
    "        try:\n",
    "            desc_dict[ii] = detail[ii]\n",
    "        except KeyError as e:\n",
    "            desc_dict[ii] = detail.get(e, list(\"-\"))\n",
    "#             print(\"{} e :: {} {} {}\".format(i, e, detail_url, desc_dict[ii]))\n",
    "            print(\"{} e :: {} {}\".format(i, e, desc_dict[ii]))\n",
    "            \n",
    "    new_data = [company_id, company_name, job_id, job_position, medium_cate_id, medium_cate, location, desc_dict['requirements'], desc_dict['main_tasks'], desc_dict['preferred_points'], desc_dict['benefits'], desc_dict['intro']]\n",
    "    \n",
    "    if (i % 150 == 0 and i != 0):\n",
    "#         print('---->{}'.format(detail_url))\n",
    "        print('---->{}'.format('getting {} detail_url'.format(i)))\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "        time.sleep(10)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return pd.DataFrame(new_data).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clickhouse_driver import Client\n",
    "\n",
    "client = Client('localhost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_database = \"\"\"\n",
    "CREATE DATABASE IF NOT EXISTS test\n",
    "\"\"\"\n",
    "client.execute(create_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('crawl',), ('default',), ('system',), ('test',)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.execute(\"SHOW DATABASES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Database에 저장하기 위한 Table을 만든다. \n",
    "\n",
    "create_tbl = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS test.wanted_job_desc (\n",
    "        `insert_time` DateTime DEFAULT now(),\n",
    "        `company_id` UInt32,\n",
    "        `company_name` String, \n",
    "        `job_id` UInt32,   \n",
    "        `job_position` String,\n",
    "        `medium_cate_id` UInt32, \n",
    "        `medium_cate` String,  \n",
    "        `location` String, \n",
    "        `requirements` Array(String),  \n",
    "        `main_tasks` Array(String),    \n",
    "        `preferred_points` Array(String),  \n",
    "        `benefits` Array(String),  \n",
    "        `intro` Array(String)\n",
    "    ) ENGINE = MergeTree PARTITION BY medium_cate_id ORDER BY insert_time SETTINGS index_granularity = 8192    \n",
    "\"\"\"\n",
    "\n",
    "client.execute(create_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`company_id`,\n",
      "`company_name`,\n",
      "`job_id`,\n",
      "`job_position`,\n",
      "`medium_cate_id`,\n",
      "`medium_cate`,\n",
      "`location`,\n",
      "`requirements`,\n",
      "`main_tasks`,\n",
      "`preferred_points`,\n",
      "`benefits`,\n",
      "`intro`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'INSERT INTO test.wanted_job_desc (company_id,company_name,job_id,job_position,medium_cate_id,medium_cate,location,requirements,main_tasks,preferred_points,benefits,intro) VALUES'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['company_id',\n",
    " 'company_name',\n",
    " 'job_id',\n",
    " 'job_position',\n",
    " 'medium_cate_id',\n",
    " 'medium_cate',\n",
    " 'location',\n",
    " 'requirements',\n",
    " 'main_tasks',\n",
    " 'preferred_points',\n",
    " 'benefits',\n",
    " 'intro']\n",
    "\n",
    "\n",
    "print('`{}`'.format('`,`'.join(columns)).replace(',', ',\\n'))\n",
    "\n",
    "val_columns = ','.join(columns)\n",
    "'INSERT INTO test.wanted_job_desc ({}) VALUES'.format(val_columns)\n",
    "\n",
    "# client.execute('INSERT INTO crawl.wanted_job_desc ({}) VALUES'.format(val_columns), _total_df.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100\n",
      "0/15\n",
      "===> To Clickhouse database\n",
      "00:00:42\n",
      "100 200\n",
      "---->gettting 150 detail_url\n",
      "00:01:14\n",
      "1/15\n",
      "===> To Clickhouse database\n",
      "00:01:46\n",
      "200 300\n",
      "2/15\n",
      "===> To Clickhouse database\n",
      "00:02:27\n",
      "300 400\n",
      "---->gettting 300 detail_url\n",
      "00:02:27\n",
      "3/15\n",
      "===> To Clickhouse database\n",
      "00:03:20\n",
      "400 500\n",
      "---->gettting 450 detail_url\n",
      "00:03:42\n",
      "4/15\n",
      "===> To Clickhouse database\n",
      "00:04:13\n",
      "500 600\n",
      "5/15\n",
      "===> To Clickhouse database\n",
      "00:05:02\n",
      "600 700\n",
      "---->gettting 600 detail_url\n",
      "00:05:03\n",
      "6/15\n",
      "===> To Clickhouse database\n",
      "00:05:59\n",
      "700 800\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-e643bc41e139>\u001b[0m in \u001b[0;36mget_jobDesc\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mdesc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'preferred_points'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-ef9c9e02b8cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0m_job_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_jobDesc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_job_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-e643bc41e139>\u001b[0m in \u001b[0;36mget_jobDesc\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mdesc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#             print(\"{} e :: {} {} {}\".format(i, e, detail_url, desc_dict[ii]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} e :: {} {} {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompany_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompany_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedium_cate_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedium_cate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'requirements'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'main_tasks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preferred_points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'benefits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'intro'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# get job detail\n",
    "# 조금씩 데이터를 설정해서 넣는 방법?? => Batch\n",
    "\n",
    "base_url = json_data['get_crawldata']['get_desc_url']\n",
    "\n",
    "import re\n",
    "import copy \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "### SET ###\n",
    "# dataframe for batch Insert\n",
    "# row_num [0:100], [101:200], ....\n",
    "# While False => insert \n",
    "\n",
    "\n",
    "batch_size = 100 # 몇개씩 insert 할 것인가\n",
    "total_step = len(job_df)//batch_size\n",
    "\n",
    "_total_df = pd.DataFrame()\n",
    "\n",
    "for step in range(total_step+1):\n",
    "    new_df = pd.DataFrame()\n",
    "    \n",
    "    if (step+1)*batch_size < len(job_df):\n",
    "        print(step*batch_size, (step+1)*batch_size)\n",
    "        \n",
    "        for i in range(step*batch_size, (step+1)*batch_size):\n",
    "            _job_df = get_jobDesc(i)\n",
    "            new_df = new_df.append(_job_df, ignore_index=False)\n",
    "            \n",
    "            \n",
    "    else:\n",
    "#         print((step)*batch_size, len(job_df)-(step)*batch_size+(step*batch_size))\n",
    "        print(step*batch_size, len(job_df))\n",
    "        for i in range(step*batch_size, len(job_df)):\n",
    "            _job_df = get_jobDesc(i)\n",
    "            new_df = new_df.append(_job_df, ignore_index=False)\n",
    "    \n",
    "    print('{}/{}'.format(step, total_step+1))\n",
    "#     new_df = new_df.append(new_df, ignore_index=True)\n",
    "    \n",
    "    print(\"===> To Clickhouse database\")\n",
    "#     client.execute('INSERT INTO test.wanted_job_desc ({}) VALUES'.format(val_columns), new_df.values.tolist())                                  \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "\n",
    "    _total_df = _total_df.append(new_df, ignore_index=True)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}